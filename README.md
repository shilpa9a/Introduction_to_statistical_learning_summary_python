# Statistical Machine Learning in Python- A summary of the book "Introduction to Statistical Learning"

Whenever someone asks me â€œHow to get started in data science?â€, I usually recommend the book ðŸ“• â€” [Introduction to Statistical Learning by Daniela Witten, Trevor Hastie, Gareth M. James, Robert Tibshirani](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf), to learn the basics of statistics and machine learning models. 

And understandably, completing a technical book while practicing it with relevant data and code is a challenge for lot of us. So, I created a concise version of the book. 

In this repo, each chapter of the book has been translated into a [jupyter notebook](https://github.com/shilpa9a/Introduction_to_statistical_learning_Summary_Python/tree/master/notebook) with summary of the key concepts, data & python code to practice. So just clone the repo and get started! :woman_technologist: 

[Notebook: Chapter 2: Statistical Learning](https://github.com/shilpa9a/Introduction_to_statistical_learning_summary_python/blob/master/notebook/Chapter_2_Statistical_Learning.ipynb) explains-

- What Is Statistical Learning?
- Assessing Model Accuracy
- Introduction to Programming language, Python

[Notebook: Chapter 3: Linear Regression](https://github.com/shilpa9a/Introduction_to_statistical_learning_summary_python/blob/master/notebook/Chapter_3_Linear_Regression.ipynb) explains-

- Linear Regression (LR)- simple, multiple
- Qualitative Predictors in LR
- Non-linear Transformations of the Predictors
- Potential Problems with least square linear regression

[Notebook: Chapter 4: Classification](https://github.com/shilpa9a/Introduction_to_statistical_learning_summary_python/blob/master/notebook/Chapter_4_Classification.ipynb) explains-

- Classification Overview
- Logistic Regression
- Linear Discriminant Analysis (LDA)
- Quadratic Discriminant Analysis (QDA)
- K-nearest neighbour

[Notebook: Chapter 5: Resampling Methods](https://github.com/shilpa9a/Introduction_to_statistical_learning_summary_python/blob/master/notebook/Chapter_5_Resampling_Methods.ipynb) explains-

* Cross-Validation
  * The Validation Set Approach
  * Leave-One-Out Cross-Validation
  * k-FoldCross-Validation
* The Bootstrap

[Notebook: Chapter 6: Linear Model Selection and Regularization](https://github.com/shilpa9a/Introduction_to_statistical_learning_summary_python/blob/master/notebook/Chapter_6_Linear_Model_Selection_and_Regularization.ipynb) explains-

* Subset Selection Models
  * Best Subset Selection
  * Forward Stepwise Selection
  * Backward Stepwise Selection
* Shrinkage Methods
  * Ridge Regression
  * The Lasso
* Dimension Reduction Methods- PCR and PLS Regression
  * Principal Components Regression
  * Partial Least Squares

*Note: Chapter-7,8,9 and 10 will be added soon.*

_____ 


### More about the book:

> "This book is intended for anyone who is interested in using modern statistical methods for modeling and prediction from data. This group includes scientists, engineers, data analysts, or quants, but also less technical individuals with degrees in non-quantitative fields such as the social sciences or business. We expect that the reader will have had at least one elementary course in statistics."

I recommend âœ…  this book because- 

1. This book (and derived notebooks in this repo) marries the statistical machine learning concepts with real-life data science problem statements. Each chapter/concept begins with a real scenerio, like - "You are a consultant who needs to advice the best medium of advertising & budgets to increase the sale of a product, using the advertising data" and explains techniques and methods step by step as we solve through it. 

2. It gives a modest introduction to statistics and mathematics behind the most used methods like:

- Regressions
- Classifications
- Decision Trees
- SVM
- Clustering
- Unsupervised Learning
- Resampling
- Cross-Validation Methods
- Dimension reduction methods

3. It also provides a ðŸ’¡ lab section at the end of each chapter. It offers R code snippets & various libraries that will come in handy to analyze data, build models, and test them. ðŸŒŸ **This repo gives the same code in python, so you are covered either way!** This will help you get started and equip you to test out the given methods & models on your own data.


Few important concepts it does not touch at all are-

- Time series data models
- Neural networks
- Deep learning
- Bayesian methods

_____ 

This is the 3rd part of my blog series, [Data science for analytical minds](https://towardsdatascience.com/data-science-for-analytical-minds-introduction-8900b8d2477f) on starting with statistics and machine learning, especially for people from non-technical backgrounds like economics, statistics, mathematics, physics etc.

Checkout its ðŸ‘‰ [introductory blog](https://medium.com/@Shilpa9a/statistical-machine-learning-in-python-b095d4af36dd) & [data quality & cleaning blog](https://towardsdatascience.com/dirty-data-quality-assessment-cleaning-measures-39efb90ad734). This is the 3rd part of the series focusing on statistics & ML basics.

This is meant to give you quick head start with most used statistical concepts with data and code to play with. For a deeper understanding of any concept, I recommend referring back to the book.

If you find any issues or have doubts, feel free to submit [issues](https://github.com/shilpa9a/Introduction_to_statistical_learning_Summary_Python/issues).

If you have any generic feedback, ideas to collaborate or anything interesting to say, you can reach me at shilpaarora992[at]gmail[dot]com.
